{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eff8bc-3b67-492f-a284-b7fe59ab5ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Saved â†’ result_catboost_single.csv\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# =========================================================\n",
    "# 1) Load & Feature Engineering\n",
    "# =========================================================\n",
    "train = pd.read_csv('train.csv')\n",
    "test  = pd.read_csv('test.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "target = train.columns[-1]\n",
    "\n",
    "def add_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    # ê°„ë‹¨ ë¬¸ìžì—´ ê²°ì¸¡ ëŒ€ì¹˜(ë²”ì£¼í˜• íŒŒì´í”„ë¼ì¸ì—ì„œ ë‹¤ì‹œ ì²˜ë¦¬ ì˜ˆì •)\n",
    "    for c in out.columns:\n",
    "        if out[c].dtype == 'object':\n",
    "            out[c] = out[c].fillna('Null')\n",
    "\n",
    "    # BMI\n",
    "    if {'height','weight'}.issubset(out.columns):\n",
    "        h_m = out['height'] / 100.0\n",
    "        out['BMI'] = out['weight'] / np.clip(h_m**2, 1e-9, None)\n",
    "\n",
    "    # í˜ˆì•• íŒŒìƒ\n",
    "    if {'systolic_blood_pressure','diastolic_blood_pressure'}.issubset(out.columns):\n",
    "        sys = out['systolic_blood_pressure']\n",
    "        dia = out['diastolic_blood_pressure']\n",
    "        out['pulse_pressure'] = sys - dia\n",
    "        out['map_pressure']   = dia + (out['pulse_pressure'] / 3.0)\n",
    "\n",
    "    # í¬ë„ë‹¹/ì½œë ˆìŠ¤í…Œë¡¤ ë¹„\n",
    "    if {'glucose','cholesterol'}.issubset(out.columns):\n",
    "        out['glu_chol_ratio'] = out['glucose'] / np.clip(out['cholesterol'], 1e-9, None)\n",
    "\n",
    "    # ê°„ë‹¨ ìƒí˜¸ìž‘ìš©\n",
    "    if {'height','weight'}.issubset(out.columns):\n",
    "        out['h_x_w'] = out['height'] * out['weight']\n",
    "\n",
    "    if 'age' in out.columns:\n",
    "        if 'activity' in out.columns:\n",
    "            act_map = {'light': 0, 'moderate': 1, 'high': 2}\n",
    "            out['_activity_level'] = out['activity'].map(act_map).fillna(-1).astype(int)\n",
    "            out['age_x_activity'] = out['age'] * out['_activity_level']\n",
    "        else:\n",
    "            out['age_x_activity'] = 0\n",
    "\n",
    "    # ë¬¸ë§¥í˜• ëŒ€í‘œ ê²°ì¸¡ ì¹˜í™˜\n",
    "    if 'medical_history' in out.columns:\n",
    "        out['medical_history'] = out['medical_history'].replace('Null', 'ë§Œì„±ì§ˆí™˜ ì—†ìŒ')\n",
    "    if 'family_medical_history' in out.columns:\n",
    "        out['family_medical_history'] = out['family_medical_history'].replace('Null', 'ì—†ìŒ')\n",
    "    return out\n",
    "\n",
    "train = add_features(train)\n",
    "test  = add_features(test)\n",
    "\n",
    "# ID ì œê±°\n",
    "for col in ['ID','id']:\n",
    "    if col in train.columns:\n",
    "        train = train.drop(columns=[col])\n",
    "    if col in test.columns:\n",
    "        test  = test.drop(columns=[col])\n",
    "\n",
    "# =========================================================\n",
    "# 2) Preprocessor (Full train ê¸°ì¤€ìœ¼ë¡œ fit)\n",
    "#    - OneHotEncoder ë²„ì „ í˜¸í™˜\n",
    "# =========================================================\n",
    "def make_preprocessor(Xdf: pd.DataFrame):\n",
    "    num_cols = [c for c in Xdf.select_dtypes(include=[np.number]).columns if c != target]\n",
    "    cat_cols = Xdf.select_dtypes(include=['object','category']).columns.tolist()\n",
    "\n",
    "    ohe_kwargs = dict(handle_unknown='ignore')\n",
    "    try:\n",
    "        OneHotEncoder(sparse_output=True, **ohe_kwargs)  # sklearn >=1.2\n",
    "        ohe_kwargs['sparse_output'] = True\n",
    "    except TypeError:\n",
    "        ohe_kwargs['sparse'] = True                      # sklearn <1.2\n",
    "\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", Pipeline([\n",
    "                (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "                (\"sc\",  StandardScaler())\n",
    "            ]), num_cols),\n",
    "            (\"cat\", Pipeline([\n",
    "                (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                (\"ohe\", OneHotEncoder(**ohe_kwargs))\n",
    "            ]), cat_cols)\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    "\n",
    "pre_full = make_preprocessor(train)\n",
    "X_full = pre_full.fit_transform(train.drop(columns=[target]))\n",
    "X_test = pre_full.transform(test)\n",
    "\n",
    "# íƒ€ê¹ƒ ìŠ¤ì¼€ì¼\n",
    "ss_full = StandardScaler()\n",
    "y_full_sc = ss_full.fit_transform(train[[target]].values).ravel()\n",
    "\n",
    "# =========================================================\n",
    "# 3) CatBoost ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ\n",
    "# =========================================================\n",
    "# CatBoost â€” ê³ ì • íŒŒë¼ë¯¸í„° (ë¡œê·¸ best)\n",
    "cat_params_fixed = {\n",
    "    'iterations': 2400,\n",
    "    'depth': 10,\n",
    "    'learning_rate': 0.029752101640529684,\n",
    "    'l2_leaf_reg': 1.8538789372311681,\n",
    "    'bagging_temperature': 1.9290162265703152,\n",
    "    'random_strength': 0.7961477702014803,\n",
    "    'loss_function': 'RMSE',\n",
    "    'random_seed': 42,\n",
    "    'verbose': False\n",
    "}\n",
    "cat_full = CatBoostRegressor(**cat_params_fixed)\n",
    "cat_full.fit(X_full, y_full_sc, verbose=False)\n",
    "pred_test_sc = cat_full.predict(X_test)\n",
    "pred_test = ss_full.inverse_transform(pred_test_sc.reshape(-1,1)).ravel()\n",
    "\n",
    "# =========================================================\n",
    "# 4) ê²°ê³¼ ì €ìž¥\n",
    "# =========================================================\n",
    "def postprocess(p):\n",
    "    return np.clip(np.round(p, 2), 0, 1)\n",
    "\n",
    "sub_catboost = sample_submission.copy()\n",
    "sub_catboost[target] = postprocess(pred_test)\n",
    "sub_catboost.to_csv('result_catboost_single.csv', index=False)\n",
    "\n",
    "print(\"ðŸ“ Saved â†’ result_catboost_single.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec18ebb",
   "metadata": {},
   "source": [
    "Best params: {'n_estimators': 531, 'max_depth': 36, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': False}\n",
    "0.15222\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
